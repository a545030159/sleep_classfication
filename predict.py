from cnn_lstm_transformer_classifier import LSTMTransformerSleepNet,SimpleSleepDataset
import torch
import pandas as pd
import json
# ä½ çš„CSVæ–‡ä»¶è·¯å¾„
csv_file = "label_data/device_info_13D1F349200080712111153007_20250623.csv"

print("ğŸš€ å¼€å§‹è®­ç»ƒ3ç±»ç¡çœ åˆ†æœŸæ¨¡å‹...")
print("="*50)

# # å¿«é€Ÿæµ‹è¯•é€‰é¡¹ - å¦‚æœæ•°æ®å¤ªå¤§ï¼Œå¯ä»¥å…ˆç”¨å°æ ·æœ¬æµ‹è¯•
USE_QUICK_TEST = False  # æ”¹ä¸ºFalseä½¿ç”¨å…¨éƒ¨æ•°æ®ï¼ŒTrueä½¿ç”¨éƒ¨åˆ†æ•°æ®æµ‹è¯•
max_samples = 50000 if USE_QUICK_TEST else None  # å¿«é€Ÿæµ‹è¯•ä½¿ç”¨5ä¸‡è¡Œæ•°æ®


def predict_realtime(model_path, csv_file, max_predict_samples=None, print_interval=1):
    """å®æ—¶é¢„æµ‹å‡½æ•° - 3ä¸ªç¡çœ é˜¶æ®µ
    
    Args:
        model_path: æ¨¡å‹æ–‡ä»¶è·¯å¾„
        csv_file: æ•°æ®æ–‡ä»¶è·¯å¾„
        max_predict_samples: æœ€å¤§é¢„æµ‹æ ·æœ¬æ•°ï¼ŒNoneè¡¨ç¤ºé¢„æµ‹æ‰€æœ‰
        print_interval: æ‰“å°é—´éš”ï¼Œ1è¡¨ç¤ºæ¯ç§’æ‰“å°ï¼Œ10è¡¨ç¤ºæ¯10ç§’æ‰“å°
    """
    
    # åŠ è½½æ¨¡å‹
    model = LSTMTransformerSleepNet(input_size=5, num_classes=3)
    model.load_state_dict(torch.load(model_path))
    model.eval()
    
    # ä½ çš„3ä¸ªæ ‡ç­¾å¯¹åº”å…³ç³»
    stage_names = ['æ¸…é†’', 'æµ…ç¡çœ ', 'æ·±ç¡çœ ']
    
    # å®æ—¶é¢„æµ‹ç¤ºä¾‹ - ä½¿ç”¨è®­ç»ƒæ—¶ä¿å­˜çš„scaler
    dataset = SimpleSleepDataset(csv_file, window_size=60, step_size=1, max_samples=None, scaler_path='sleep_scaler.pkl')
    
    

    predictions = []
    
    # ç¡®å®šé¢„æµ‹æ•°é‡
    if max_predict_samples is None:
        predict_count = len(dataset)
    else:
        predict_count = min(max_predict_samples, len(dataset))
    
    print(f"å¼€å§‹é¢„æµ‹ï¼Œæ€»å…±{predict_count}ä¸ªæ ·æœ¬ï¼Œæ¯{print_interval}ç§’æ‰“å°ä¸€æ¬¡ç»“æœ")
    print("-" * 60)
    



    with torch.no_grad():
        for i in range(predict_count):
            sample, _ = dataset[i]
            sample = sample.unsqueeze(0)  # æ·»åŠ batchç»´åº¦
            
            output = model(sample)
            predicted_class = torch.argmax(output, dim=1).item()
            
            predictions.append(stage_names[predicted_class])
            
            # æ¯100ä¸ªæ ·æœ¬æ˜¾ç¤ºä¸€æ¬¡è¿›åº¦
            if (i + 1) % 100 == 0:
                progress = (i + 1) / predict_count * 100
                print(f"è¿›åº¦: {i+1}/{predict_count} ({progress:.1f}%)")
    
    # ç»Ÿè®¡é¢„æµ‹ç»“æœ
    stage_counts = {}
    for pred in predictions:
        stage = pred
        stage_counts[stage] = stage_counts.get(stage, 0) + 1
    
    print(f"\né¢„æµ‹æ€»ç»“:")
    print(f"é¢„æµ‹æ ·æœ¬æ•°: {len(predictions)}")
    return predictions

try:
    print("âœ… è®­ç»ƒå®Œæˆï¼")
    
    print("\nğŸ”® å¼€å§‹å®æ—¶é¢„æµ‹...")
    print("="*50)
    
    # é¢„æµ‹é€‰é¡¹
    print("é€‰æ‹©é¢„æµ‹æ¨¡å¼:")
    print("1. æ¯ç§’é¢„æµ‹ - é¢„æµ‹100ç§’")
    print("2. æ¯10ç§’é¢„æµ‹ - é¢„æµ‹1000ç§’") 
    print("3. å¿«é€Ÿé¢„æµ‹ - é¢„æµ‹æ‰€æœ‰å¯èƒ½çš„æ ·æœ¬")
    
    # ä¸åŒé¢„æµ‹æ¨¡å¼
    # æ¨¡å¼1: æ¯ç§’æ˜¾ç¤ºï¼Œé¢„æµ‹100ç§’
    print("\nğŸ“Š æ¨¡å¼1: æ¯ç§’é¢„æµ‹ç»“æœ")
    predictions = predict_realtime('transformer_sleep_model.pth', csv_file, 
                                    max_predict_samples=None, print_interval=1)
    df = pd.read_csv(csv_file, encoding='utf-8')
    df['predictions'] = ['æ— æ•ˆæ•°æ®']* 29 + predictions + (len(df) -len(predictions)-29)*['æ— æ•ˆæ•°æ®']
    df.to_csv("predictions.csv")
    print(f"âœ… é¢„æµ‹å®Œæˆ")
    
    # ä¿å­˜é¢„æµ‹ç»“æœ
    with open('transformer_sleep_predictions_1s.json', 'w', encoding='utf-8') as f:
        json.dump(predictions, f, ensure_ascii=False, indent=2)
    

    print("ğŸ“„ é¢„æµ‹ç»“æœå·²ä¿å­˜åˆ°: sleep_predictions_1s.json ")
    
except FileNotFoundError:
    print("âŒ æ‰¾ä¸åˆ°CSVæ–‡ä»¶ï¼Œè¯·æ£€æŸ¥æ–‡ä»¶è·¯å¾„ï¼")
    print("å½“å‰æŸ¥æ‰¾æ–‡ä»¶:", csv_file)
    print("è¯·å°†ä½ çš„CSVæ–‡ä»¶æ”¾åœ¨è„šæœ¬åŒç›®å½•ä¸‹ï¼Œæˆ–ä¿®æ”¹csv_fileå˜é‡")

except Exception as e:
    print(f"âŒ å‡ºé”™äº†: {e}")
    import traceback
    traceback.print_exc()
    print("è¯·æ£€æŸ¥æ•°æ®æ ¼å¼æ˜¯å¦æ­£ç¡®")
    print("ç¡®ä¿CSVåŒ…å«åˆ—: create_time, breath_line, heart_line, distance, signal_intensity, label")
        